[["index.html", "Statistical Learning and Machine Learning with R Preface Target Audience Whats Covered? Acknowledgements License", " Statistical Learning and Machine Learning with R Ruoqing Zhu 2021-08-26 Preface Welcome to Statistical Learning and Machine Learning with R! I started this project during the summer of 2018 when I was preparing for the Stat 432 course. At that time, our faculty member Dr. David Dalpiaz, had decided to move to The Ohio State University (although he later on moved back to UIUC). David introduced to me this awesome way of publishing website on GitHub, which is a very efficient approach for developing courses. Since I was also teaching Stat 542 (Statistical Learning) for several years, I figured it could be beneficial to integrate what I have to this existing book by David and use it as the R material for both courses. For Stat 542, the main focus is to learn the numerical optimization behind these learning algorithms, and also be familiar with the theoretical background. As you can tell, I am not being very creative on the name, so `SMLR it is. You can find the source file of this book on my GitHub. Target Audience This book can be suitable for students ranging from advanced undergraduate to first/second year Ph.D students who have prior knowledge in statistics. Although a student at the masters level will likely benefit most from the material. Previous experience with both basic mathematics (mainly linear algebra), statistical modeling (such as linear regressions) and R are assumed. Whats Covered? I currently plan to include the following topics: Basic Knowledge in R Linear and Penalized Linear Models Numerical Optimization Basics Classification Non-parametric Statistical Models Machine Learning Models Unsupervised Learning Appendix The goal of this book is to introduce not only how to run some of the popular statistical learning models in R, but also know the algorithms and programming techniques for solving these models. For each section, the difficulty will gradually increase from an undergraduate level to a graduate level. It will be served as a supplement to An Introduction to Statistical Learning (James et al. 2013) for STAT 432 - Basics of Statistical Learning and The Elements of Statistical Learning: Data Mining, Inference, and Prediction (Hastie, Tibshirani, and Friedman 2001) for STAT 542 - Statistical Learning at the University of Illinois at Urbana-Champaign. This book is under active development. Hence, you may encounter errors ranging from typos to broken code, to poorly explained topics. If you do, please let me know! Simply send an email and I will make the changes as soon as possible (rqzhu AT illinois DOT edu). Or, if you know R Markdown and are familiar with GitHub, make a pull request and fix an issue yourself!. These contributions will be acknowledged. Acknowledgements The initial contents are derived from Dr. David Dalpiazs book. My STAT 542 course materials are also inspired by Dr. Feng Liang and Dr. John Marden who developed earlier versions of this course. And I also incorporated many online resources, which I cannot put into a comprehensive list. License This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. References "],["1-r-and-rstudio.html", "Chapter 1 R and RStudio 1.1 Installing R and RStudio 1.2 Resources and Guides 1.3 Basic Mathematical Operations 1.4 Data Objects 1.5 Readin and save data 1.6 Using and defining functions 1.7 Distribution and random numbers 1.8 Using packages and other resources 1.9 Practice questions", " Chapter 1 R and RStudio 1.1 Installing R and RStudio The first step is to download and install R and RStudio. Most steps should be self-explanatory. You can also find many online guides for step-by-step instruction, such as this YouTube video. However, be aware that some details may have been changed over the years. After installing both, open your RStudio, you should see four panes, which can be seen below: Source pane on top-left where you write code in to files Console on bottom-left where the code is inputted into R Environment (and other tabs) on top-right where you can see current variables and objects you defined File (and other tabs) on bottom-right which is essentially a file borrower We will mainly use the left two panes. You can either directly input code into the console to run for results, or edit your code in a file and run them in chunks or as a whole. 1.2 Resources and Guides There are many online resources for how to use R, RStudio. For example, David Dalpiazs other online book Applied Statistics with R contains an introduction to using them. There are also other online documentation such as Install R and RStudio R tutorial Data in R Play-list (video) R and RStudio Play-list (video) It is worth to mention that once you become an advanced user, and possibly a developer of R packages using C/C++ (add-on of R for performing specific tasks), and you also happen to use Windows like I do, you will have to install Rtools that contains the gcc compilers. This is also needed if you want to install any R package from a source (.tar.gz) file instead of using the so-called binaries (.zip files). 1.3 Basic Mathematical Operations Basic R calculations and operations should be self-explanatory. Try to type-in the following commands into your R console and start to explore yourself. Lines with a # in the front are comments, which will not be executed. Lines with ## in the front are outputs you should expect. # Basic mathematical operations 1 + 3 ## [1] 4 1 - 3 ## [1] -2 1 * 3 ## [1] 3 1 / 3 ## [1] 0.3333333 3^5 ## [1] 243 4^(-1/2) ## [1] 0.5 pi ## [1] 3.141593 # some math functions sqrt(4) ## [1] 2 exp(1) ## [1] 2.718282 log(3) ## [1] 1.098612 log2(16) ## [1] 4 log(15, base = 3) ## [1] 2.464974 factorial(5) ## [1] 120 sin(pi) ## [1] 1.224606e-16 If you want to see more information about a particular function or operator in R, the easiest way is to get the reference document. Put a question mark in front of a function name: # In a default R console window, this will open up a web browser. # In RStudio, this will be displayed at the Help window at the bottom-right penal (Help tab). ?log10 ?cos 1.4 Data Objects Data objects can be a complicated topic for people who never used R before. The most common data objects are vector, matrix, list, and data.frame. They are defined using a specific syntax. To define a vector, we use c followed by (), where the elements within the parenthesis are separated using comma. You can save the vector and name as something else. For example # creating a vector c(1,2,3,4) ## [1] 1 2 3 4 c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;) ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; # define a new vector object, called `x` x = c(1,1,1,0,0,0) After defining this object x, it should also appear on your top-right environment pane. To access elements in an object, we use the [] operator, like a C programming reference style. # getting the second element in x x[2] ## [1] 1 # getting the second to the fourth element in x x[2:4] ## [1] 1 1 0 Similarly, we can create and access elements in a matrix: # create a matrix by providing all of its elements # the elements are filled to the matrix by column matrix(c(1,2,3,4), 2, 2) ## [,1] [,2] ## [1,] 1 3 ## [2,] 2 4 # create a matrix by column-bind vectors y = c(1,0,1,0,1,0) cbind(x, y) ## x y ## [1,] 1 1 ## [2,] 1 0 ## [3,] 1 1 ## [4,] 0 0 ## [5,] 0 1 ## [6,] 0 0 # access elements in a matrix # Note that in R, upper and lower cases are treated as two different objects X = matrix(c(1:16), 4, 4) X ## [,1] [,2] [,3] [,4] ## [1,] 1 5 9 13 ## [2,] 2 6 10 14 ## [3,] 3 7 11 15 ## [4,] 4 8 12 16 X[2, 3] ## [1] 10 X[1, ] ## [1] 1 5 9 13 # getting a sub-matrix of X X[1:2, 3:4] ## [,1] [,2] ## [1,] 9 13 ## [2,] 10 14 Mathematical operations on vectors and matrices are, by default, element-wise. For matrix multiplications, you should use %*%. # adding two vectors (x + y)^2 ## [1] 4 1 4 0 1 0 # getting the length of a vector length(x) ## [1] 6 # matrix multiplication X %*% X ## [,1] [,2] [,3] [,4] ## [1,] 90 202 314 426 ## [2,] 100 228 356 484 ## [3,] 110 254 398 542 ## [4,] 120 280 440 600 # getting the dimension of a matrix dim(X) ## [1] 4 4 # A warning will be issued when R detects something wrong # Results may still be produced however y + c(1,2,3,4) ## Warning in y + c(1, 2, 3, 4): longer object length is not a multiple of shorter object length ## [1] 2 2 4 4 2 2 list() creates a list of objects (of any type). However, some operators cannot be directly applied to a list in a similar way as to vectors or matrices. Model fitting results in R are usually stored as a list. For example, the lm() function, which will be introduced later. # creating a list x = list(c(1,2), &quot;hello&quot;, matrix(c(1,2,3,4), 2, 2)) # accessing its elements using double brackets `[[]]` x[[1]] ## [1] 1 2 data.frame() creates a list of vectors of equal length, and display them as a matrix-like object, in which each vector is a column of the matrix. It is mainly used for storing data. This will be our most frequently used data object for analysis. For example, in the famous iris data, the first four columns are numerical variables, while the last column is a categorical variable with three levels: setosa, versicolor, and virginica: # The iris data is included with base R, so we can use them directly # This will create a copy of the data into your environment data(iris) # the head function peeks the first several rows of the dataset head(iris, n = 3) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa # each column usually contains a column (variable) name colnames(iris) ## [1] &quot;Sepal.Length&quot; &quot;Sepal.Width&quot; &quot;Petal.Length&quot; &quot;Petal.Width&quot; &quot;Species&quot; # data frame can be called by each individual column, which will be a vector # iris$Species iris$Species[2:4] ## [1] setosa setosa setosa ## Levels: setosa versicolor virginica # the summary function can be used to view summary statistics of all variables summary(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## Min. :4.300 Min. :2.000 Min. :1.000 Min. :0.100 setosa :50 ## 1st Qu.:5.100 1st Qu.:2.800 1st Qu.:1.600 1st Qu.:0.300 versicolor:50 ## Median :5.800 Median :3.000 Median :4.350 Median :1.300 virginica :50 ## Mean :5.843 Mean :3.057 Mean :3.758 Mean :1.199 ## 3rd Qu.:6.400 3rd Qu.:3.300 3rd Qu.:5.100 3rd Qu.:1.800 ## Max. :7.900 Max. :4.400 Max. :6.900 Max. :2.500 factor is a special type of vector. It is frequently used to store a categorical variable with more than two categories. The last column of the iris data is a factor. You need to be a little bit careful when dealing with factor variables when during modeling since some functions do not take care of them automatically or they do it in a different way than you thought. For example, changing a factor variable into numerical ones will ignore any potential relationship among different categories. levels(iris$Species) ## [1] &quot;setosa&quot; &quot;versicolor&quot; &quot;virginica&quot; as.numeric(iris$Species) ## [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1.5 Readin and save data Data can be imported from a variety of sources. More commonly, a dataset can be stored in .txt and .csv files. Such data reading methods require specific structures in the source file: the first row should contain column names, and there should be equal number of elements in each row. Hence you should always check your file before reading them in. # read-in data birthrate = read.csv(&quot;data/birthrate.csv&quot;) head(birthrate) ## Year Birthrate ## 1 1917 183.1 ## 2 1918 183.9 ## 3 1919 163.1 ## 4 1920 179.5 ## 5 1921 181.4 ## 6 1922 173.4 # to see how many observations (rows) and variables (columns) in a dataset dim(birthrate) ## [1] 87 2 R data can also be saved into other formats. The more efficient way, assuming that you are going to load these file back to R in the future, is to save them as .RData file. Usually, for a larger dataset, this reduces the time spend on reading the data. # saving a object to .RData file save(birthrate, file = &quot;mydata.RData&quot;) # you can specify multiple objects to be saved into the same file save(birthrate, iris, file = &quot;mydata.RData&quot;) # load the data again back to your environment load(&quot;mydata.RData&quot;) # alternatively, you can also save data to a .csv file write.csv(birthrate, file = &quot;mydata.csv&quot;) # you can notice that this .csv file contains an extra column of &quot;ID number&quot;, without a column name # Hence, when you read this file back into R, you should specify `row.names = 1` to indicate that. # Otherwise this will produce an error read.csv(file = &quot;mydata.csv&quot;, row.names = 1) 1.6 Using and defining functions We have already used many functions. You can also define your own functions, and even build them into packages (more on this later) for other people to use. This is the main advantage of R. For example, lets consider writing a function that returns the minimum and maximum of a vector. Suppose we already know the min() and max() functions. myrange &lt;- function(x) # x is the argument that your function takes in { return(c(min(x), max(x))) # return a vector that contains two elements } x = 1:10 myrange(x) ## [1] 1 10 # R already has this function range(x) ## [1] 1 10 1.7 Distribution and random numbers Three distributions that are most frequently used in this course are Bernoulli, Gaussian (normal), and \\(t\\) distributions. Bernoulli distributions can be used to describe binary variables, while Gaussian distribution is often used to describe continuous ones. The following code generates some random variables # read the documentation of rbinom() using ?rbinom x = rbinom(100, 1, 0.4) table(x) ## x ## 0 1 ## 62 38 However, this result cannot be replicated by others, since the next time we run this code, the random numbers will be different. Hence it is important to set and keep the random seed when a random algorithm is involved. The following code will always generate the same result set.seed(1) x = rbinom(100, 1, 0.4) y = rnorm(100) # by default, this is mean 0 and variance 1 table(x) ## x ## 0 1 ## 57 43 hist(y) boxplot(y ~ x) 1.8 Using packages and other resources Packages are written and contributed to R by individuals. They provide additional features (functions or data) that serve particular needs. For example, the ggplot2 package is developed by the RStudio team that provides nice features to plot data. We will have more examples of this later on, but first, lets install and load the package so that we can use these features. More details will be provided in the data visualization section. # to install a package install.packages(&quot;ggplot2&quot;) # to load the package library(ggplot2) # use the ggplot() function to produce a plot # Sepal.Length is the horizontal axis # Sepal.Width is the vertical axis # Species labels are used as color ggplot(iris, aes(Sepal.Length, Sepal.Width, colour = Species)) + geom_point() You may also noticed that in our previous examples, all tables only displayed the first several rows. One may be interested in looking at the entire dataset, however, it would take too much space to display the whole table. Here is a package that would allow you to display it in a compact window. It also provides searching and sorting tools. You can integrate this into your R Markdown reports. library(DT) datatable(iris, filter = &quot;top&quot;, rownames = FALSE, options = list(pageLength = 5)) Often times, you may want to perform a new task and you dont know what function can be used to achieve that. Google Search or Stack Overflow are probably your best friends. I used to encounter this problem: I have a list of objects, and each of them is a vector. I then need to extract the first element of all these vectors. However, doing this using a for-loop can be slow, and I am also interested in a cleaner code. So I found this post, which provided a simple answer: # create the list a = list(c(1,1,1), c(2,2,2), c(3,3,3)) # extract the first element in each vector of the list sapply(a, &quot;[[&quot;, 1) ## [1] 1 2 3 1.9 Practice questions Attach a new numerical column to the iris data, as the product of Petal.Length and Petal.Width and name the column as Petal.Prod. iris = cbind(iris, &quot;Petal.Prod&quot; = iris$Petal.Length*iris$Petal.Width) head(iris) Attach a new numerical column to the iris data, with value 1 if the observation is setosa, 2 for versicolor and 3 for virginica, and name the column as Species.Num. iris = cbind(iris, &quot;Species.Num&quot; = as.numeric(iris$Species)) head(iris) Change Species.Num to a factor variable such that it takes value Type1 if the observation is setosa and NA otherwise. iris$Species.Num = as.factor(ifelse(iris$Species == &quot;setosa&quot;, &quot;Type1&quot;, &quot;NA&quot;)) head(iris) Define a function that takes in a numerical vector, and output the mean of that vector. Do this without using the mean() and sum() function. mymean &lt;- function(x) { sum = 0 for (i in 1:length(x)) sum = sum + x[i] return(sum = sum / length(x)) } x = 1:10 mymean(x) mean(x) "],["2-rmarkdown.html", "Chapter 2 RMarkdown 2.1 Basics and Resources 2.2 Formatting Text 2.3 Adding R Code 2.4 Importing Data 2.5 Working Directory 2.6 Plotting 2.7 Chunk Options 2.8 Adding Math with LaTeX 2.9 Output Options 2.10 Try It!", " Chapter 2 RMarkdown 2.1 Basics and Resources R Markdown is a built-in feature of RStudio. It integrates plain text with chunks of R code in to a single file, which is extremely useful when constructing class notes or building a website. A .rmd file can be compiled into nice-looking .html, .pdf, and .docx file. For example, this entire guide is created using R Markdown. With RStudio, you can install R Markdown from R console using the following code. Note that this should be automatically done the first time you create and compile a .rmd file in RStudio. # Install R Markdown from CRAN install.packages(&quot;rmarkdown&quot;) Again there are many online guides for R Markdown, and these may not be the best ones. R Markdown: The Definitive Guide R Markdown Cheat Sheet R Markdown Play-list (video) To get started, create an R Markdown template file by clicking File -&gt; New File -&gt; R Markdown... You can then Knit the template file and start to explore its features. Please note that this guide is provided in the .html format. However, your homework report should be in .pdf format. This can be done by selecting the Knit to PDF option from the Knit button. Again there are many online guides, and these may not be the best ones. R Markdown Cheat Sheet R Markdown Play-list (video) 2.2 Formatting Text Formatting text is easy. Bold can be done using ** or __ before and after the text. Italics can be done using * or _ before and after the text. For example, This is bold. This is italics. and this is bold italics. This text appears as monospaced. Unordered list element 1. Unordered list element 2. Unordered list element 3. Ordered list element 1. Ordered list element 2. Ordered list element 3. We could mix lists and links. Note that a link can be constructed in the format [display text](http link). If colors are desired, we can customize it using, for example, [\\textcolor{blue}{display text}](http link). But this only works in .pdf format. For .html, use &lt;span style=\"color: red;\"&gt;text&lt;/span&gt;. A default link: RMarkdown Documentation colored link 1: (Not shown because it only works in PDF) colored link 2: Table Generator (only works in HTML) Tables are sometimes tricky using Markdown. See the above link for a helpful Markdown table generator. Note that you can also adjust the alignment by using a : sign. A B C 1 2 3 Middle Left Right 2.3 Adding R Code So far we have only used Markdown to create the text part. This is useful by itself, but the real power of RMarkdown comes when we add R. There are two ways we can do this. We can use R code chunks, or run R inline. 2.3.1 R Chunks The following is an example of an R code chunk. Start the chunk with ```{r} and end with ```: ```{r} \\(\\quad\\) set.seed(123) \\(\\quad\\) rnorm(5) ``` This generates five random observations from the standard normal distribution. We also set the seed so that the results can be later on replicated. The result looks like the following set.seed(123) rnorm(5) ## [1] -0.56047565 -0.23017749 1.55870831 0.07050839 0.12928774 # define function get_sd = function(x, biased = FALSE) { n = length(x) - 1 * !biased sqrt((1 / n) * sum((x - mean(x)) ^ 2)) } # generate random sample data set.seed(42) (test_sample = rnorm(n = 10, mean = 2, sd = 5)) ## [1] 8.8547922 -0.8234909 3.8156421 5.1643130 4.0213416 1.4693774 9.5576100 1.5267048 12.0921186 1.6864295 # run function on generated data get_sd(test_sample) ## [1] 4.177244 There is a lot going on here. In the .Rmd file, notice the syntax that creates and ends the chunk. Also note that example_chunk is the chunk name. Everything between the start and end syntax must be valid R code. Chunk names are not necessary, but can become useful as your documents grow in size. In this example, we define a function, generate some random data in a reproducible manner, displayed the data, then ran our function. 2.3.2 Inline R R can also be run in the middle of the exposition. For example, the mean of the data we generated is 4.7364838. 2.4 Importing Data When using RMarkdown, any time you knit your document to its final form, say .html, a number of programs run in the background. Your current R environment seen in RStudio will be reset. Any objects you created while working interactively inside RStudio will be ignored. Essentially a new R session will be spawned in the background and the code in your document is run there from start to finish. For this reason, things such as importing data must be explicitly coded into your document. library(readr) example_data = read_table(&quot;data/skincancer.txt&quot;) The above loads the online file. In many cases, you will load a file that is locally stored in your own computer. In that case, you can either specify the full file path, or simply use, for example read_csv(\"filename.csv\") if that file is stored at your working directory. The working directory will usually be the directory that contains your .Rmd file. You are recommended to reference data in this manner. Note that we use the newer read_csv() from the readr package instead of the default read.csv(). 2.5 Working Directory Whenever R code is run, there is always a current working directory. This allows for relative references to external files, in addition to absolute references. Since the working directory when knitting a file is always the directory that contains the .Rmd file, it can be helpful to set the working directory inside RStudio to match while working interactively. To do so, select Session &gt; Set Working Directory &gt; To Source File Location while editing a .Rmd file. This will set the working directory to the path that contains the .Rmd. You can also use getwd() and setwd() to manipulate your working directory programmatically. These should only be used interactively. Using them inside an RMarkdown document would likely result in lessened reproducibility. As of recent RStudio updates, this practice is not always necessary when working interactively. If lines of code are being Output Inline, then the working directory is automatically the directory which contains the .Rmd file. 2.6 Plotting The following generates a simple plot, which displays the skin cancer mortality. By default, the figure is aligned on the left, with size 3 by 5 inches. plot(Mort ~ Lat, data = example_data) In our R introduction, we used ggplot2 to create a more interesting plot. You may also polish a plot with basic functions. Notice it is huge in the resulting document, since we have modified some chunk options (fig.height = 6, fig.width = 8) in the RMarkdown file to manipulate its size. plot(Mort ~ Lat, data = example_data, xlab = &quot;Latitude&quot;, ylab = &quot;Skin Cancer Mortality Rate&quot;, main = &quot;Skin Cancer Mortality vs. State Latitude&quot;, pch = 19, cex = 1.5, col = &quot;deepskyblue&quot;) But you can also notice that the labels and the plots becomes disproportional when the figure size is set too small. This can be resolved using a scaling option such as out.width = '60%, but enlarge the original figure size. We also align the figure at the center using fig.align = 'center' 2.7 Chunk Options We have already seen chunk options fig.height, fig.width, and out.width which modified the size of plots from a particular chunk. There are many chunk options, but we will discuss some others which are frequently used including; eval, echo, message, and warning. If you noticed, the plot above was displayed without showing the code. install.packages(&quot;rmarkdown&quot;) ?log View(mpg) Using eval = FALSE the above chunk displays the code, but it is not run. Weve already discussed not wanting install code to run. The ? code pulls up documentation of a function. This will spawn a browser window when knitting, or potentially crash during knitting. Similarly, using View() is an issue with RMarkdown. Inside RStudio, this would pull up a window which displays the data. However, when knitting, R runs in the background and RStudio is not modifying the View() function. This, on OSX especially, usually causes knitting to fail. ## [1] &quot;Hello World!&quot; Above, we see output, but no code! This is done using echo = FALSE, which is often useful. x = 1:10 y = 1:10 summary(lm(y ~ x)) ## ## Call: ## lm(formula = y ~ x) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.661e-16 -1.157e-16 4.273e-17 2.153e-16 4.167e-16 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.123e-15 2.458e-16 4.571e+00 0.00182 ** ## x 1.000e+00 3.961e-17 2.525e+16 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.598e-16 on 8 degrees of freedom ## Multiple R-squared: 1, Adjusted R-squared: 1 ## F-statistic: 6.374e+32 on 1 and 8 DF, p-value: &lt; 2.2e-16 The above code produces a warning, for reasons we will discuss later. Sometimes, in final reports, it is nice to hide these, which we have done here. message = FALSE and warning = FALSE can be used to do so. Messages are often created when loading packages to give the user information about the effects of loading the package. These should be suppressed in final reports. Be careful about suppressing these messages and warnings too early in an analysis as you could potentially miss important information! 2.8 Adding Math with LaTeX Another benefit of RMarkdown is the ability to add Latex for mathematics typesetting. Like R code, there are two ways we can include Latex; displaystyle and inline. Note that use of LaTeX is somewhat dependent on the resulting file format. For example, it cannot be used at all with .docx. To use it with .pdf you must have LaTeX installed on your machine. With .html the LaTeX is not actually rendered during knitting, but actually rendered in your browser using MathJax. 2.8.1 Displaystyle LaTeX Displaystyle is used for larger equations which appear centered on their own line. This is done by putting $$ before and after the mathematical equation. \\[ \\widehat \\sigma = \\sqrt{\\frac{1}{n - 1}\\sum_{i=1}^{n}(x_i - \\bar{x})^2} \\] 2.8.2 Inline LaTex We could mix LaTeX commands in the middle of exposition, for example: \\(t = 2\\). We could actually mix R with Latex as well! For example: \\(\\bar{x} = 4.7364838\\). 2.9 Output Options At the beginning of the document, there is a code which describes some metadata and settings of the document. The default code looks like title: &quot;R Notebook&quot; output: html_notebook You can easily add your name and date to it, and add a Table of Contents, using toc: yes. Note that the following code would specify the theme of an html file. title: &quot;My RMarkdown Template&quot; author: &quot;Your Name&quot; date: &quot;Aug 26, 2021&quot; output: html_document: toc: yes You can edit this yourself, or click the settings button at the top of the document and select Output Options.... Here you can explore other themes and syntax highlighting options, as well as many additional options. Using this method will automatically modify this information in the document. 2.10 Try It! Be sure to play with this document! Change it. Break it. Fix it. The best way to learn RMarkdown (or really almost anything) is to try, fail, then find out what you did wrong. RStudio has provided a number of beginner tutorials which have been greatly improved recently and detail many of the specifics potentially not covered in this document. RMarkdown is continually improving, and this document covers only the very basics. "],["3-linear-regression.html", "Chapter 3 Linear Regression 3.1 Example: real estate data 3.2 Notation and Basic Properties 3.3 Using the lm() Function 3.4 Model Selection Criteria and Algorithm", " Chapter 3 Linear Regression This chapter severs several purposes. First, we will review some basic knowledge of linear regression. This includes the concept of vector space, projection, which leads to estimating parameters of a linear regression. Most of these knowledge are covered in the prerequisite so you shouldnt find these concepts too difficult to understand. Secondly, we will mainly use the lm() function as an example to demonstrate some features of R. This includes extracting results, visualizations, handling categorical variables, prediction and model selection. These concepts will be useful for other models. 3.1 Example: real estate data This Real Estate data is provided on the UCI machine learning repository. The goal of this dataset is to predict the unit house price based on six different covariates: date: The transaction date (for example, 2013.250=2013 March, 2013.500=2013 June, etc.) age: The house age (unit: year) distance: The distance to the nearest MRT station (unit: meter) stores: The number of convenience stores in the living circle on foot (integer) latitude: Latitude (unit: degree) longitude: Longitude (unit: degree) price: House price of unit area realestate = read.csv(&quot;data/realestate.csv&quot;, row.names = 1) library(DT) datatable(realestate, filter = &quot;top&quot;, rownames = FALSE, options = list(pageLength = 8)) dim(realestate) ## [1] 414 7 3.2 Notation and Basic Properties We usually denote the observed covariates data as the design matrix \\(\\mathbf{X}\\), with dimension \\(n \\times p\\). Hence in this case, the dimension of \\(\\mathbf{X}\\) is \\(414 \\times 7\\). The \\(j\\)th variable is simply the \\(j\\)th column of this matrix, which is denoted as \\(\\mathbf{x}_j\\). The outcome \\(\\mathbf{y}\\) (price) is a vector of length \\(414\\). Please note that we usually use a bold symbol to represent a vector, while for a single element (scalar), such as the \\(j\\)th variable of subject \\(i\\), we use \\(x_{ij}\\). \\(\\bX\\) A linear regression concerns modeling the relationship (in matrix form) \\[\\by_{n \\times 1} = \\bX_{n \\times p} \\bbeta_{p \\times 1} + \\bepsilon_{n \\times 1}\\] And we know that the solution is obtained by minimizing the residual sum of squares (RSS): \\[ \\begin{align} \\widehat{\\bbeta} &amp;= \\underset{\\bbeta}{\\argmin} \\sum_{i=1}^n \\left(y_i - x_i^\\T \\bbeta \\right)^2 \\\\ &amp;= \\underset{\\bbeta}{\\argmin} \\big( \\mathbf y - \\mathbf{X} \\boldsymbol \\beta \\big)^\\T \\big( \\mathbf y - \\mathbf{X} \\boldsymbol \\beta \\big) \\end{align} \\] Classic solution can be obtained by taking the derivative of RSS w.r.t \\(\\bbeta\\) and set it to zero. This leads to the well known normal equation: \\[ \\begin{align} \\frac{\\partial \\text{RSS}}{\\partial \\bbeta} &amp;= -2 \\bX^\\T (\\by - \\bX \\bbeta) \\doteq 0 \\\\ \\Longrightarrow \\quad \\bX^\\T \\by &amp;= \\bX^\\T \\bX \\bbeta \\end{align} \\] Assuming that \\(\\bX\\) is full rank, then \\(\\bX^\\T \\bX\\) is invertible. Then, we have \\[ \\widehat{\\bbeta} = (\\bX^\\T \\bX)^{-1}\\bX^\\T \\by \\] Some additional concepts are frequently used. The fitted values \\(\\widehat \\by\\) are essentially the prediction of the original \\(n\\) training data points: \\[ \\begin{align} \\widehat{\\by} =&amp; \\bX \\bbeta\\\\ =&amp; \\underbrace{\\bX (\\bX^\\T \\bX)^{-1}\\bX^\\T}_{\\bH} \\by \\\\ \\doteq&amp; \\bH_{n \\times n} \\by \\end{align} \\] where \\(\\bH\\) is called the hat matrix. It is a projection matrix that projects any vector (\\(\\by\\) in our case) onto the column space of \\(\\bX\\). A project matrix enjoys two properties Symmetric: \\(\\bH^\\T = \\bH\\) Idempotent \\(\\bH\\bH = \\bH\\) The residuals \\(\\br\\) can also be obtained using the hat matrix: \\[ \\br = \\by - \\widehat \\by = (\\bI - \\bH) \\by\\] From the properties of a projection matrix, we also know that \\(\\br\\) should be orthogonal to any vector from the column space of \\(\\bX\\). Hence, \\[\\bX^\\T \\br = \\mathbf{0}_{p \\times 1}\\] The residuals is also used to estimate the error variance: \\[\\widehat\\sigma^2 = \\frac{1}{n-p} \\sum_{i=1}^n r_i^2 = \\frac{\\text{RSS}}{n-p}\\] When the data are indeed generated from a linear model, and with suitable conditions on the design matrix and random errors \\(\\bepsilon\\), we can conclude that \\(\\widehat \\bbeta\\) is an unbiased estimator of \\(\\bbeta\\). Its variance-covariance matrix satisfies \\[ \\begin{align} \\Var(\\widehat \\bbeta) &amp;= \\Var\\big( (\\bX^\\T \\bX)^{-1}\\bX^\\T \\by \\big) \\nonumber \\\\ &amp;= \\Var\\big( (\\bX^\\T \\bX)^{-1}\\bX^\\T (\\bX \\bbeta + \\bepsilon) \\big) \\nonumber \\\\ &amp;= \\Var\\big( (\\bX^\\T \\bX)^{-1}\\bX^\\T \\bepsilon) \\big) \\nonumber \\\\ &amp;= (\\bX^\\T \\bX)^{-1}\\bX^\\T \\bX (\\bX^\\T \\bX)^{-1} \\bI \\sigma^2 \\nonumber \\\\ &amp;= (\\bX^\\T \\bX)^{-1}\\sigma^2 \\end{align} \\] All of the above mentioned results are already implemented in R through the lm() function to fit a linear regression. 3.3 Using the lm() Function Lets consider a simple regression model that uses age and distance to explain price. We will save the fitted object as realestat.lmfit realestat.lmfit = lm(price ~ age + distance, data = realestate) This example contains three major components: data = specifies the dataset The outcome variable should be on the left hand side of ~ The covariates should be on the right hand side of ~ To look at the detailed model fitting results, use the summary() function summary(realestat.lmfit) ## ## Call: ## lm(formula = price ~ age + distance, data = realestate) ## ## Residuals: ## Min 1Q Median 3Q Max ## -36.032 -4.742 -1.037 4.533 71.930 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 49.8855858 0.9677644 51.547 &lt; 2e-16 *** ## age -0.2310266 0.0420383 -5.496 6.84e-08 *** ## distance -0.0072086 0.0003795 -18.997 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 9.73 on 411 degrees of freedom ## Multiple R-squared: 0.4911, Adjusted R-squared: 0.4887 ## F-statistic: 198.3 on 2 and 411 DF, p-value: &lt; 2.2e-16 This can be viewed as either a convex optimization problem or projections on the \\(n\\) dimensional vector space. 3.3.1 Linear regression as an optimization # generate data for a simple linear regression set.seed(20) n = 100 x &lt;- cbind(1, rnorm(n)) y &lt;- x %*% c(1, 0.5) + rnorm(n) # calculate the residual sum of squares for a grid of beta values rss &lt;- function(b, x, y) sum((y - x %*% b)^2) b1 &lt;- b2 &lt;- seq(0, 2, length= 20) z = matrix(apply(expand.grid(b1, b2), 1, rss, x, y), 20, 20) # 3d plot for RSS par(mar = c(1,1,3,1)) persp(b1, b2, z, xlab = &quot;beta 1&quot;, ylab = &quot;beta 2&quot;, zlab = &quot;RSS&quot;, main=&quot;Residual Sum of Squares&quot;, col = &quot;springgreen&quot;, shade = 0.6, theta = 30, phi = 5) # The solution can be solved by any optimization algorithm optim(c(0, 0), rss, x = x, y = y)$par ## [1] 1.088813 0.679870 3.3.2 Linear regression as projections Another view is through projections in vector space. Consider each column of \\(\\mathbf{X}\\) as a vector, and project \\(\\mathbf{y}\\) onto the column space of \\(\\mathbf{X}\\). The project is \\[ \\widehat{\\mathbf{y}} = \\mathbf{X} (\\mathbf{X}^\\text{T} \\mathbf{X})^{-1}\\mathbf{X}^\\text{T} \\mathbf{y} \\doteq {\\mathbf{H}} \\mathbf{y}, \\] where \\(\\mathbf{H}\\) is a projection matrix. And the residuals are simply \\[ \\widehat{\\mathbf{e}} = \\mathbf{y} - \\widehat{\\mathbf{y}} = (\\mathbf{I} - \\mathbf{H}) \\mathbf{y} \\] When the number of variables is large, inverting \\(\\mathbf{X}^\\text{T} \\mathbf{X}\\) is expansive. The R function lm() does not calculate the inverse directly. Instead, QR decomposition can be used. You can try a larger \\(n\\) and \\(p\\) to see a significant difference. This is only for demonstration. They are not required for our course. # generate 100 observations with 3 variables set.seed(1) n = 1000 p = 500 x = matrix(rnorm(n*p), n, p) X = cbind(1, x) # the design matrix, including 1 as the first column # define the true beta, the first entry is the intercept b = as.matrix(c(1, 1, 0.5, rep(0, p-2))) # generate training y with Gaussian errors y = X %*% b + rnorm(n) # fit a linear regression model lm.fit = lm(y ~ x) # look at the coefficients beta hat head(lm.fit$coef) ## (Intercept) x1 x2 x3 x4 x5 ## 1.016479750 1.026143517 0.496792668 -0.017272409 0.005193304 0.034639107 # using normal equations by inverting the X&#39;X matrix: b = (X&#39;X)^-1 X&#39;y # however, this is very slow # check ?solve system.time({beta_hat = solve(t(X) %*% X) %*% t(X) %*% y}) ## user system elapsed ## 0.33 0.00 0.33 head(beta_hat) ## [,1] ## [1,] 1.016479750 ## [2,] 1.026143517 ## [3,] 0.496792668 ## [4,] -0.017272409 ## [5,] 0.005193304 ## [6,] 0.034639107 # you can avoid the inversion by specifying the linear equation system X&#39;X b = X&#39;y system.time({beta_hat = solve(t(X) %*% X, t(X) %*% y)}) ## user system elapsed ## 0.15 0.00 0.14 # A better approach is to use QR decomposition or the Cholesky decomposition # The following codes are not necessarily efficient, they are only for demonstration purpose # QR decomposition # direct calling the qr.coef function system.time({beta_hat = qr.coef(qr(X), y)}) ## user system elapsed ## 0.13 0.00 0.13 # or system.time({beta_hat = qr.solve(t(X) %*% X, t(X) %*% y)}) ## user system elapsed ## 0.17 0.00 0.17 # if you want to see what Q and R are QR = qr(X) Q = qr.Q(QR) R = qr.R(QR) # get inverse of R, you can check R %*% R_inv yourself # the backsolve/forwardsolve functions can be used to solve AX = b for upper/lower triangular matrix A # ?backsolve R_inv = backsolve(R, diag(p+1), upper.tri = TRUE, transpose = FALSE) beta_hat = R_inv %*% t(Q) %*% y # Cholesky Decomposition # the chol function gives upper triangular matrix # crossprod(X) = X&#39;X system.time({ R = chol(crossprod(X)) w = backsolve(R, t(X) %*% y, upper.tri = TRUE, transpose = TRUE) beta_hat = backsolve(R, w, upper.tri = TRUE, transpose = FALSE) }) ## user system elapsed ## 0.12 0.00 0.13 # or equivalently R = t(chol(crossprod(X))) w = forwardsolve(R, t(X) %*% y, upper.tri = FALSE, transpose = FALSE) beta_hat = forwardsolve(R, w, upper.tri = FALSE, transpose = TRUE) # the transpose = TRUE means that we are solving for R&#39;b = w instead of Rb = w 3.4 Model Selection Criteria and Algorithm 3.4.1 Example: diabetes dataset We use the diabetes dataset from the lars package as a demonstration of model selection. library(lars) ## Loaded lars 1.2 data(diabetes) diab = data.frame(cbind(diabetes$x, &quot;Y&quot; = diabetes$y)) # A Brief Description of the Diabetes Data (Efron et al, 2004): # Ten baseline variables: age, sex, body mass index, average blood pressure, and six blood serum # measurements were obtained for each of n = 442 diabetes patients, as well as # the response of interest, a quantitative measure of disease progression one year after baseline lmfit=lm(Y~., data=diab) # When we use normal distribution likelihood for the errors, there are 12 parameters # The function AIC() directly calculates the AIC score from a lm() fitted model n = nrow(diab) p = 11 # ?AIC AIC(lmfit) # a build-in function for calculating AIC using -2log likelihood ## [1] 4795.985 n*log(sum(residuals(lmfit)^2/n)) + n + n*log(2*pi) + 2 + 2*p ## [1] 4795.985 # In many standard R packages, the AIC is calculated by removing some constants from the likelihood # We will use this value as the default # ?extractAIC extractAIC(lmfit) # AIC for the full model ## [1] 11.000 3539.643 RSS = sum(residuals(lmfit)^2) n*log(RSS/n) + 2*p ## [1] 3539.643 # so the BIC for the full model is extractAIC(lmfit, k = log(n)) ## [1] 11.000 3584.648 n*log(RSS/n) + log(n)*p ## [1] 3584.648 # if we want to calculate Cp, use the formula RSS + 2*p*summary(lmfit)$sigma^2 ## [1] 1328502 # however, the scale of this is usually very large, we may consider the following version RSS/summary(lmfit)$sigma^2 + 2*p - n ## [1] 11 The step() function can be used to select the best model based on specified model selection criteria. # Model selection: stepwise algorithm # ?step # this function shows every step during the model selection step(lmfit, direction=&quot;both&quot;, k = 2) # k = 2 (AIC) is default; ## Start: AIC=3539.64 ## Y ~ age + sex + bmi + map + tc + ldl + hdl + tch + ltg + glu ## ## Df Sum of Sq RSS AIC ## - age 1 82 1264066 3537.7 ## - hdl 1 663 1264646 3537.9 ## - glu 1 3080 1267064 3538.7 ## - tch 1 3526 1267509 3538.9 ## &lt;none&gt; 1263983 3539.6 ## - ldl 1 5799 1269782 3539.7 ## - tc 1 10600 1274583 3541.3 ## - sex 1 45000 1308983 3553.1 ## - ltg 1 56015 1319998 3556.8 ## - map 1 72103 1336086 3562.2 ## - bmi 1 179028 1443011 3596.2 ## ## Step: AIC=3537.67 ## Y ~ sex + bmi + map + tc + ldl + hdl + tch + ltg + glu ## ## Df Sum of Sq RSS AIC ## - hdl 1 646 1264712 3535.9 ## - glu 1 3001 1267067 3536.7 ## - tch 1 3543 1267608 3536.9 ## &lt;none&gt; 1264066 3537.7 ## - ldl 1 5751 1269817 3537.7 ## - tc 1 10569 1274635 3539.4 ## + age 1 82 1263983 3539.6 ## - sex 1 45831 1309896 3551.4 ## - ltg 1 55963 1320029 3554.8 ## - map 1 73850 1337915 3560.8 ## - bmi 1 179079 1443144 3594.2 ## ## Step: AIC=3535.9 ## Y ~ sex + bmi + map + tc + ldl + tch + ltg + glu ## ## Df Sum of Sq RSS AIC ## - glu 1 3093 1267805 3535.0 ## - tch 1 3247 1267959 3535.0 ## &lt;none&gt; 1264712 3535.9 ## - ldl 1 7505 1272217 3536.5 ## + hdl 1 646 1264066 3537.7 ## + age 1 66 1264646 3537.9 ## - tc 1 26840 1291552 3543.2 ## - sex 1 46382 1311094 3549.8 ## - map 1 73536 1338248 3558.9 ## - ltg 1 97509 1362221 3566.7 ## - bmi 1 178537 1443249 3592.3 ## ## Step: AIC=3534.98 ## Y ~ sex + bmi + map + tc + ldl + tch + ltg ## ## Df Sum of Sq RSS AIC ## - tch 1 3686 1271491 3534.3 ## &lt;none&gt; 1267805 3535.0 ## - ldl 1 7472 1275277 3535.6 ## + glu 1 3093 1264712 3535.9 ## + hdl 1 738 1267067 3536.7 ## + age 1 0 1267805 3537.0 ## - tc 1 26378 1294183 3542.1 ## - sex 1 44686 1312491 3548.3 ## - map 1 82154 1349959 3560.7 ## - ltg 1 102520 1370325 3567.3 ## - bmi 1 189970 1457775 3594.7 ## ## Step: AIC=3534.26 ## Y ~ sex + bmi + map + tc + ldl + ltg ## ## Df Sum of Sq RSS AIC ## &lt;none&gt; 1271491 3534.3 ## + tch 1 3686 1267805 3535.0 ## + glu 1 3532 1267959 3535.0 ## + hdl 1 395 1271097 3536.1 ## + age 1 11 1271480 3536.3 ## - ldl 1 39378 1310869 3545.7 ## - sex 1 41858 1313349 3546.6 ## - tc 1 65237 1336728 3554.4 ## - map 1 79627 1351119 3559.1 ## - bmi 1 190586 1462077 3594.0 ## - ltg 1 294094 1565585 3624.2 ## ## Call: ## lm(formula = Y ~ sex + bmi + map + tc + ldl + ltg, data = diab) ## ## Coefficients: ## (Intercept) sex bmi map tc ldl ltg ## 152.1 -226.5 529.9 327.2 -757.9 538.6 804.2 step(lmfit, direction=&quot;backward&quot;, trace=0) # trace=0 will not print intermediate results ## ## Call: ## lm(formula = Y ~ sex + bmi + map + tc + ldl + ltg, data = diab) ## ## Coefficients: ## (Intercept) sex bmi map tc ldl ltg ## 152.1 -226.5 529.9 327.2 -757.9 538.6 804.2 step(lm(Y~1, data=diab), scope=list(upper=lmfit, lower=~1), direction=&quot;forward&quot;, trace=0) ## ## Call: ## lm(formula = Y ~ bmi + ltg + map + tc + sex + ldl, data = diab) ## ## Coefficients: ## (Intercept) bmi ltg map tc sex ldl ## 152.1 529.9 804.2 327.2 -757.9 -226.5 538.6 step(lmfit, direction=&quot;both&quot;, k=log(n), trace=0) # BIC (the default value for k=2, which corresponds to AIC) ## ## Call: ## lm(formula = Y ~ sex + bmi + map + tc + ldl + ltg, data = diab) ## ## Coefficients: ## (Intercept) sex bmi map tc ldl ltg ## 152.1 -226.5 529.9 327.2 -757.9 538.6 804.2 The leaps package will calculate the best model of each model size. Then we can add the penalties to the model fitting result and conclude the best model. ########################################################################## # Best subset model selection (Cp, AIC, and BIC): leaps ########################################################################## library(leaps) # performs an exhaustive search over models, and gives back the best model # (with low RSS) of each size. # the default maximum model size is nvmax=8 RSSleaps=regsubsets(as.matrix(diab[,-11]),diab[,11]) summary(RSSleaps, matrix=T) ## Subset selection object ## 10 Variables (and intercept) ## Forced in Forced out ## age FALSE FALSE ## sex FALSE FALSE ## bmi FALSE FALSE ## map FALSE FALSE ## tc FALSE FALSE ## ldl FALSE FALSE ## hdl FALSE FALSE ## tch FALSE FALSE ## ltg FALSE FALSE ## glu FALSE FALSE ## 1 subsets of each size up to 8 ## Selection Algorithm: exhaustive ## age sex bmi map tc ldl hdl tch ltg glu ## 1 ( 1 ) &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; ## 2 ( 1 ) &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; ## 3 ( 1 ) &quot; &quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; ## 4 ( 1 ) &quot; &quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; ## 5 ( 1 ) &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot; &quot; ## 6 ( 1 ) &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; ## 7 ( 1 ) &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot; ## 8 ( 1 ) &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; RSSleaps=regsubsets(as.matrix(diab[,-11]),diab[,11], nvmax=10) summary(RSSleaps,matrix=T) ## Subset selection object ## 10 Variables (and intercept) ## Forced in Forced out ## age FALSE FALSE ## sex FALSE FALSE ## bmi FALSE FALSE ## map FALSE FALSE ## tc FALSE FALSE ## ldl FALSE FALSE ## hdl FALSE FALSE ## tch FALSE FALSE ## ltg FALSE FALSE ## glu FALSE FALSE ## 1 subsets of each size up to 10 ## Selection Algorithm: exhaustive ## age sex bmi map tc ldl hdl tch ltg glu ## 1 ( 1 ) &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; ## 2 ( 1 ) &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; ## 3 ( 1 ) &quot; &quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; ## 4 ( 1 ) &quot; &quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; ## 5 ( 1 ) &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot; &quot; ## 6 ( 1 ) &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot; &quot; &quot;*&quot; &quot; &quot; ## 7 ( 1 ) &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot; &quot; ## 8 ( 1 ) &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; ## 9 ( 1 ) &quot; &quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; ## 10 ( 1 ) &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; &quot;*&quot; sumleaps=summary(RSSleaps,matrix=T) names(sumleaps) # components returned by summary(RSSleaps) ## [1] &quot;which&quot; &quot;rsq&quot; &quot;rss&quot; &quot;adjr2&quot; &quot;cp&quot; &quot;bic&quot; &quot;outmat&quot; &quot;obj&quot; sumleaps$which ## (Intercept) age sex bmi map tc ldl hdl tch ltg glu ## 1 TRUE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## 2 TRUE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE TRUE FALSE ## 3 TRUE FALSE FALSE TRUE TRUE FALSE FALSE FALSE FALSE TRUE FALSE ## 4 TRUE FALSE FALSE TRUE TRUE TRUE FALSE FALSE FALSE TRUE FALSE ## 5 TRUE FALSE TRUE TRUE TRUE FALSE FALSE TRUE FALSE TRUE FALSE ## 6 TRUE FALSE TRUE TRUE TRUE TRUE TRUE FALSE FALSE TRUE FALSE ## 7 TRUE FALSE TRUE TRUE TRUE TRUE TRUE FALSE TRUE TRUE FALSE ## 8 TRUE FALSE TRUE TRUE TRUE TRUE TRUE FALSE TRUE TRUE TRUE ## 9 TRUE FALSE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## 10 TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE msize=apply(sumleaps$which,1,sum) n=dim(diab)[1] p=dim(diab)[2] Cp = sumleaps$rss/(summary(lmfit)$sigma^2) + 2*msize - n; AIC = n*log(sumleaps$rss/n) + 2*msize; BIC = n*log(sumleaps$rss/n) + msize*log(n); cbind(Cp, sumleaps$cp) ## Cp ## 1 148.352561 148.352561 ## 2 47.072229 47.072229 ## 3 30.663634 30.663634 ## 4 21.998461 21.998461 ## 5 9.148045 9.148045 ## 6 5.560162 5.560162 ## 7 6.303221 6.303221 ## 8 7.248522 7.248522 ## 9 9.028080 9.028080 ## 10 11.000000 11.000000 cbind(BIC, sumleaps$bic) # It seems regsubsets uses a formula for BIC different from the one we used. ## BIC ## 1 3665.879 -174.1108 ## 2 3586.331 -253.6592 ## 3 3575.249 -264.7407 ## 4 3571.077 -268.9126 ## 5 3562.469 -277.5210 ## 6 3562.900 -277.0899 ## 7 3567.708 -272.2819 ## 8 3572.720 -267.2702 ## 9 3578.585 -261.4049 ## 10 3584.648 -255.3424 BIC-sumleaps$bic # But the two just differ by a constant, so won&#39;t affect the model selection result. ## 1 2 3 4 5 6 7 8 9 10 ## 3839.99 3839.99 3839.99 3839.99 3839.99 3839.99 3839.99 3839.99 3839.99 3839.99 n*log(sum((diab[,11] - mean(diab[,11]))^2/n)) # the difference is the score of an intercept model ## [1] 3839.99 # Rescale Cp, AIC, BIC to (0,1). inrange &lt;- function(x) { (x - min(x)) / (max(x) - min(x)) } Cp = sumleaps$cp; Cp = inrange(Cp); BIC = sumleaps$bic; BIC = inrange(BIC); AIC = n*log(sumleaps$rss/n) + 2*msize; AIC = inrange(AIC); plot(range(msize), c(0, 1.1), type=&quot;n&quot;, xlab=&quot;Model Size (with Intercept)&quot;, ylab=&quot;Model Selection Criteria&quot;) points(msize, Cp, col=&quot;red&quot;, type=&quot;b&quot;) points(msize, AIC, col=&quot;blue&quot;, type=&quot;b&quot;) points(msize, BIC, col=&quot;black&quot;, type=&quot;b&quot;) legend(&quot;topright&quot;, lty=rep(1,3), col=c(&quot;red&quot;, &quot;blue&quot;, &quot;black&quot;), legend=c(&quot;Cp&quot;, &quot;AIC&quot;, &quot;BIC&quot;)) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
