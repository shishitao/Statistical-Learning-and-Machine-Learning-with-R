<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 12 Lasso Regression | Statistical Learning and Machine Learning with R</title>
  <meta name="description" content="Chapter 12 Lasso Regression | Statistical Learning and Machine Learning with R" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 12 Lasso Regression | Statistical Learning and Machine Learning with R" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://teazrq.github.io/SMLR/" />
  
  
  <meta name="github-repo" content="teazrq/SMLR" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 12 Lasso Regression | Statistical Learning and Machine Learning with R" />
  
  
  

<meta name="author" content="Ruoqing Zhu" />


<meta name="date" content="2021-06-23" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="favicon.ico" type="image/x-icon" />
<link rel="prev" href="ridge-regression.html"/>
<link rel="next" href="splines.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistical Learning and Machine Learning with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#target-audience"><i class="fa fa-check"></i>Target Audience</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#whats-covered"><i class="fa fa-check"></i>Whatâ€™s Covered?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i>License</a></li>
</ul></li>
<li class="part"><span><b>I Basics Knowledge</b></span></li>
<li class="chapter" data-level="1" data-path="r-rstudio-and-r-markdown.html"><a href="r-rstudio-and-r-markdown.html"><i class="fa fa-check"></i><b>1</b> R, RStudio and R Markdown</a></li>
<li class="chapter" data-level="2" data-path="r-basics.html"><a href="r-basics.html"><i class="fa fa-check"></i><b>2</b> R Basics</a><ul>
<li class="chapter" data-level="2.1" data-path="r-basics.html"><a href="r-basics.html#resources-and-guides"><i class="fa fa-check"></i><b>2.1</b> Resources and Guides</a></li>
<li class="chapter" data-level="2.2" data-path="r-basics.html"><a href="r-basics.html#basic-mathematical-operations"><i class="fa fa-check"></i><b>2.2</b> Basic Mathematical Operations</a></li>
<li class="chapter" data-level="2.3" data-path="r-basics.html"><a href="r-basics.html#data-objects"><i class="fa fa-check"></i><b>2.3</b> Data Objects</a></li>
<li class="chapter" data-level="2.4" data-path="r-basics.html"><a href="r-basics.html#read-in-data-from-other-sources"><i class="fa fa-check"></i><b>2.4</b> Read-in Data from Other Sources</a></li>
<li class="chapter" data-level="2.5" data-path="r-basics.html"><a href="r-basics.html#using-packages"><i class="fa fa-check"></i><b>2.5</b> Using Packages</a></li>
<li class="chapter" data-level="2.6" data-path="r-basics.html"><a href="r-basics.html#explore-yourself"><i class="fa fa-check"></i><b>2.6</b> Explore Yourself</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="rmarkdown-basics.html"><a href="rmarkdown-basics.html"><i class="fa fa-check"></i><b>3</b> RMarkdown Basics</a><ul>
<li class="chapter" data-level="3.1" data-path="rmarkdown-basics.html"><a href="rmarkdown-basics.html#acknowledgement"><i class="fa fa-check"></i><b>3.1</b> Acknowledgement</a></li>
<li class="chapter" data-level="3.2" data-path="rmarkdown-basics.html"><a href="rmarkdown-basics.html#getting-started"><i class="fa fa-check"></i><b>3.2</b> Getting Started</a></li>
<li class="chapter" data-level="3.3" data-path="rmarkdown-basics.html"><a href="rmarkdown-basics.html#adding-r"><i class="fa fa-check"></i><b>3.3</b> Adding <code>R</code></a><ul>
<li class="chapter" data-level="3.3.1" data-path="rmarkdown-basics.html"><a href="rmarkdown-basics.html#r-chunks"><i class="fa fa-check"></i><b>3.3.1</b> <code>R</code> Chunks</a></li>
<li class="chapter" data-level="3.3.2" data-path="rmarkdown-basics.html"><a href="rmarkdown-basics.html#inline-r"><i class="fa fa-check"></i><b>3.3.2</b> Inline <code>R</code></a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="rmarkdown-basics.html"><a href="rmarkdown-basics.html#importing-data"><i class="fa fa-check"></i><b>3.4</b> Importing Data</a></li>
<li class="chapter" data-level="3.5" data-path="rmarkdown-basics.html"><a href="rmarkdown-basics.html#working-directory"><i class="fa fa-check"></i><b>3.5</b> Working Directory</a></li>
<li class="chapter" data-level="3.6" data-path="rmarkdown-basics.html"><a href="rmarkdown-basics.html#packages"><i class="fa fa-check"></i><b>3.6</b> Packages</a></li>
<li class="chapter" data-level="3.7" data-path="rmarkdown-basics.html"><a href="rmarkdown-basics.html#plotting"><i class="fa fa-check"></i><b>3.7</b> Plotting</a></li>
<li class="chapter" data-level="3.8" data-path="rmarkdown-basics.html"><a href="rmarkdown-basics.html#chunk-options"><i class="fa fa-check"></i><b>3.8</b> Chunk Options</a></li>
<li class="chapter" data-level="3.9" data-path="rmarkdown-basics.html"><a href="rmarkdown-basics.html#adding-math-with-latex"><i class="fa fa-check"></i><b>3.9</b> Adding Math with LaTeX</a><ul>
<li class="chapter" data-level="3.9.1" data-path="rmarkdown-basics.html"><a href="rmarkdown-basics.html#displaystyle-latex"><i class="fa fa-check"></i><b>3.9.1</b> Displaystyle LaTeX</a></li>
<li class="chapter" data-level="3.9.2" data-path="rmarkdown-basics.html"><a href="rmarkdown-basics.html#inline-latex"><i class="fa fa-check"></i><b>3.9.2</b> Inline LaTex</a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="rmarkdown-basics.html"><a href="rmarkdown-basics.html#output-options"><i class="fa fa-check"></i><b>3.10</b> Output Options</a></li>
<li class="chapter" data-level="3.11" data-path="rmarkdown-basics.html"><a href="rmarkdown-basics.html#try-it"><i class="fa fa-check"></i><b>3.11</b> Try It!</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="basics-of-probability-and-statistics.html"><a href="basics-of-probability-and-statistics.html"><i class="fa fa-check"></i><b>4</b> Basics of Probability and Statistics</a><ul>
<li class="chapter" data-level="4.1" data-path="basics-of-probability-and-statistics.html"><a href="basics-of-probability-and-statistics.html#random-number-generation"><i class="fa fa-check"></i><b>4.1</b> Random Number Generation</a></li>
<li class="chapter" data-level="4.2" data-path="basics-of-probability-and-statistics.html"><a href="basics-of-probability-and-statistics.html#summary-statistics-and-data-visualization"><i class="fa fa-check"></i><b>4.2</b> Summary Statistics and Data Visualization</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="modeling-basics.html"><a href="modeling-basics.html"><i class="fa fa-check"></i><b>5</b> Modeling Basics</a><ul>
<li class="chapter" data-level="5.1" data-path="modeling-basics.html"><a href="modeling-basics.html#fitting-linear-regression"><i class="fa fa-check"></i><b>5.1</b> Fitting Linear Regression</a></li>
<li class="chapter" data-level="5.2" data-path="modeling-basics.html"><a href="modeling-basics.html#model-diagnostics"><i class="fa fa-check"></i><b>5.2</b> Model Diagnostics</a></li>
<li class="chapter" data-level="5.3" data-path="modeling-basics.html"><a href="modeling-basics.html#variable-transformations-and-interactions"><i class="fa fa-check"></i><b>5.3</b> Variable Transformations and Interactions</a></li>
<li class="chapter" data-level="5.4" data-path="modeling-basics.html"><a href="modeling-basics.html#model-selection"><i class="fa fa-check"></i><b>5.4</b> Model Selection</a></li>
<li class="chapter" data-level="5.5" data-path="modeling-basics.html"><a href="modeling-basics.html#prediction"><i class="fa fa-check"></i><b>5.5</b> Prediction</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="optimization.html"><a href="optimization.html"><i class="fa fa-check"></i><b>6</b> Optimization</a></li>
<li class="part"><span><b>II Unsupervised Learning</b></span></li>
<li class="chapter" data-level="7" data-path="k-means-clustering.html"><a href="k-means-clustering.html"><i class="fa fa-check"></i><b>7</b> K-means Clustering</a><ul>
<li class="chapter" data-level="7.1" data-path="k-means-clustering.html"><a href="k-means-clustering.html#basic-concepts"><i class="fa fa-check"></i><b>7.1</b> Basic Concepts</a></li>
<li class="chapter" data-level="7.2" data-path="k-means-clustering.html"><a href="k-means-clustering.html#example-1-iris-data"><i class="fa fa-check"></i><b>7.2</b> Example 1: <code>iris</code> data</a></li>
<li class="chapter" data-level="7.3" data-path="k-means-clustering.html"><a href="k-means-clustering.html#example-2-clustering-of-image-pixels"><i class="fa fa-check"></i><b>7.3</b> Example 2: clustering of image pixels</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html"><i class="fa fa-check"></i><b>8</b> Hierarchical Clustering</a><ul>
<li class="chapter" data-level="8.1" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#basic-concepts-1"><i class="fa fa-check"></i><b>8.1</b> Basic Concepts</a></li>
<li class="chapter" data-level="8.2" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#example-1-iris-data-1"><i class="fa fa-check"></i><b>8.2</b> Example 1: <code>iris</code> data</a></li>
<li class="chapter" data-level="8.3" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#example-2-rna-expression-data"><i class="fa fa-check"></i><b>8.3</b> Example 2: RNA Expression Data</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="principle-component-analysis.html"><a href="principle-component-analysis.html"><i class="fa fa-check"></i><b>9</b> Principle Component Analysis</a><ul>
<li class="chapter" data-level="9.1" data-path="principle-component-analysis.html"><a href="principle-component-analysis.html#basic-concepts-2"><i class="fa fa-check"></i><b>9.1</b> Basic Concepts</a><ul>
<li class="chapter" data-level="9.1.1" data-path="principle-component-analysis.html"><a href="principle-component-analysis.html#note-scaling"><i class="fa fa-check"></i><b>9.1.1</b> Note: Scaling</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="principle-component-analysis.html"><a href="principle-component-analysis.html#example-1-iris-data-2"><i class="fa fa-check"></i><b>9.2</b> Example 1: <code>iris</code> Data</a></li>
<li class="chapter" data-level="9.3" data-path="principle-component-analysis.html"><a href="principle-component-analysis.html#example-2-handwritten-digits"><i class="fa fa-check"></i><b>9.3</b> Example 2: Handwritten Digits</a></li>
</ul></li>
<li class="part"><span><b>III Linear and Penalized Linear Regressions</b></span></li>
<li class="chapter" data-level="10" data-path="linear-regression-and-model-selection.html"><a href="linear-regression-and-model-selection.html"><i class="fa fa-check"></i><b>10</b> Linear Regression and Model Selection</a><ul>
<li class="chapter" data-level="10.1" data-path="linear-regression-and-model-selection.html"><a href="linear-regression-and-model-selection.html#basic-concepts-3"><i class="fa fa-check"></i><b>10.1</b> Basic Concepts</a><ul>
<li class="chapter" data-level="10.1.1" data-path="linear-regression-and-model-selection.html"><a href="linear-regression-and-model-selection.html#linear-regression-as-an-optimization"><i class="fa fa-check"></i><b>10.1.1</b> Linear regression as an optimization</a></li>
<li class="chapter" data-level="10.1.2" data-path="linear-regression-and-model-selection.html"><a href="linear-regression-and-model-selection.html#linear-regression-as-projections"><i class="fa fa-check"></i><b>10.1.2</b> Linear regression as projections</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="linear-regression-and-model-selection.html"><a href="linear-regression-and-model-selection.html#model-selection-criteria-and-algorithm"><i class="fa fa-check"></i><b>10.2</b> Model Selection Criteria and Algorithm</a><ul>
<li class="chapter" data-level="10.2.1" data-path="linear-regression-and-model-selection.html"><a href="linear-regression-and-model-selection.html#example-diabetes-dataset"><i class="fa fa-check"></i><b>10.2.1</b> Example: <code>diabetes</code> dataset</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="ridge-regression.html"><a href="ridge-regression.html"><i class="fa fa-check"></i><b>11</b> Ridge Regression</a><ul>
<li class="chapter" data-level="11.1" data-path="ridge-regression.html"><a href="ridge-regression.html#basic-concepts-4"><i class="fa fa-check"></i><b>11.1</b> Basic Concepts</a><ul>
<li class="chapter" data-level="11.1.1" data-path="ridge-regression.html"><a href="ridge-regression.html#correlated-variables-and-convexity"><i class="fa fa-check"></i><b>11.1.1</b> Correlated Variables and Convexity</a></li>
<li class="chapter" data-level="11.1.2" data-path="ridge-regression.html"><a href="ridge-regression.html#example-1-the-prostate-cancer-data"><i class="fa fa-check"></i><b>11.1.2</b> Example 1: The Prostate Cancer Data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="lasso-regression.html"><a href="lasso-regression.html"><i class="fa fa-check"></i><b>12</b> Lasso Regression</a><ul>
<li class="chapter" data-level="12.1" data-path="lasso-regression.html"><a href="lasso-regression.html#basic-concepts-5"><i class="fa fa-check"></i><b>12.1</b> Basic Concepts</a><ul>
<li class="chapter" data-level="12.1.1" data-path="lasso-regression.html"><a href="lasso-regression.html#variable-selection-property"><i class="fa fa-check"></i><b>12.1.1</b> Variable Selection Property</a></li>
<li class="chapter" data-level="12.1.2" data-path="lasso-regression.html"><a href="lasso-regression.html#example-1-the-prostate-cancer-data-1"><i class="fa fa-check"></i><b>12.1.2</b> Example 1: The Prostate Cancer Data</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Nonlinear and Nonparametric Models</b></span></li>
<li class="chapter" data-level="13" data-path="splines.html"><a href="splines.html"><i class="fa fa-check"></i><b>13</b> Splines</a><ul>
<li class="chapter" data-level="13.1" data-path="splines.html"><a href="splines.html#basic-concepts-6"><i class="fa fa-check"></i><b>13.1</b> Basic Concepts</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="smoothing-splines.html"><a href="smoothing-splines.html"><i class="fa fa-check"></i><b>14</b> Smoothing Splines</a><ul>
<li class="chapter" data-level="14.1" data-path="smoothing-splines.html"><a href="smoothing-splines.html#basic-concepts-7"><i class="fa fa-check"></i><b>14.1</b> Basic Concepts</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="kernel-regression.html"><a href="kernel-regression.html"><i class="fa fa-check"></i><b>15</b> Kernel Regression</a><ul>
<li class="chapter" data-level="15.1" data-path="kernel-regression.html"><a href="kernel-regression.html#basic-concepts-8"><i class="fa fa-check"></i><b>15.1</b> Basic Concepts</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="kernel-density-estimation.html"><a href="kernel-density-estimation.html"><i class="fa fa-check"></i><b>16</b> Kernel Density Estimation</a><ul>
<li class="chapter" data-level="16.1" data-path="kernel-density-estimation.html"><a href="kernel-density-estimation.html#basic-concepts-9"><i class="fa fa-check"></i><b>16.1</b> Basic Concepts</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>17</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/teazrq/SMLR" target="blank">&copy; 2021 Ruoqing Zhu</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical Learning and Machine Learning with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="lasso-regression" class="section level1">
<h1><span class="header-section-number">Chapter 12</span> Lasso Regression</h1>

<div id="basic-concepts-5" class="section level2">
<h2><span class="header-section-number">12.1</span> Basic Concepts</h2>
<p>Lasso regression solves the following <span class="math inline">\(\ell_1\)</span> penalized linear model</p>
<p><span class="math display">\[\widehat {\boldsymbol\beta}^{\,\text{lasso}} = \underset{{\boldsymbol\beta}}{\arg\min} \,\, \lVert \mathbf y- \mathbf X{\boldsymbol\beta}\rVert^2 + \lambda \lVert {\boldsymbol\beta}\rVert_1\]</span></p>
<p>We cannot obtain an analytical solution in a general case. However, for a special case with orthogonal design, i.e., <span class="math inline">\(\mathbf X^\text{T}\mathbf X= bI\)</span>, we can see that the Lasso solution is essentially applying a soft-thresholding function to each parameter in the OLS solution.</p>
<div id="variable-selection-property" class="section level3">
<h3><span class="header-section-number">12.1.1</span> Variable Selection Property</h3>
<p>Lasso regression has a variable selection property, which may shrink some coefficients to exactly 0 if the effect of that variable is small.</p>
<div class="sourceCode" id="cb207"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb207-1"><a href="lasso-regression.html#cb207-1"></a>    <span class="kw">library</span>(MASS)</span>
<span id="cb207-2"><a href="lasso-regression.html#cb207-2"></a>    <span class="kw">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb207-3"><a href="lasso-regression.html#cb207-3"></a>    n =<span class="st"> </span><span class="dv">100</span></span>
<span id="cb207-4"><a href="lasso-regression.html#cb207-4"></a>    </span>
<span id="cb207-5"><a href="lasso-regression.html#cb207-5"></a>    <span class="co"># create highly correlated variables and a linear model</span></span>
<span id="cb207-6"><a href="lasso-regression.html#cb207-6"></a>    X =<span class="st"> </span><span class="kw">mvrnorm</span>(n, <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>), <span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="fl">-0.5</span>, <span class="fl">-0.5</span>, <span class="dv">1</span>), <span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb207-7"><a href="lasso-regression.html#cb207-7"></a>    y =<span class="st"> </span><span class="kw">rnorm</span>(n, <span class="dt">mean =</span> <span class="fl">0.1</span><span class="op">*</span>X[,<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span><span class="fl">0.5</span><span class="op">*</span>X[,<span class="dv">2</span>])</span>
<span id="cb207-8"><a href="lasso-regression.html#cb207-8"></a>    </span>
<span id="cb207-9"><a href="lasso-regression.html#cb207-9"></a>    <span class="co"># compare parameter estimates</span></span>
<span id="cb207-10"><a href="lasso-regression.html#cb207-10"></a>    <span class="kw">summary</span>(<span class="kw">lm</span>(y<span class="op">~</span>X<span class="dv">-1</span>))<span class="op">$</span>coef</span></code></pre></div>
<pre><code>##     Estimate Std. Error  t value     Pr(&gt;|t|)
## X1 0.1403512  0.1279464 1.096953 2.753501e-01
## X2 0.5686526  0.1272897 4.467390 2.124799e-05</code></pre>
<p>We can see that the optimal solution is at around <code>(0.140, 0.569)</code>, which are both nonzero.</p>
<div class="sourceCode" id="cb209"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb209-1"><a href="lasso-regression.html#cb209-1"></a>    beta1 &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="fl">0.5</span>, <span class="fl">0.75</span>, <span class="fl">0.005</span>)</span>
<span id="cb209-2"><a href="lasso-regression.html#cb209-2"></a>    beta2 &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="fl">0.25</span>, <span class="dv">1</span>, <span class="fl">0.005</span>)</span>
<span id="cb209-3"><a href="lasso-regression.html#cb209-3"></a>    allbeta &lt;-<span class="st"> </span><span class="kw">data.matrix</span>(<span class="kw">expand.grid</span>(beta1, beta2))</span>
<span id="cb209-4"><a href="lasso-regression.html#cb209-4"></a>    </span>
<span id="cb209-5"><a href="lasso-regression.html#cb209-5"></a>    <span class="co"># the OLS objective function contour</span></span>
<span id="cb209-6"><a href="lasso-regression.html#cb209-6"></a>    rss &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">apply</span>(allbeta, <span class="dv">1</span>, <span class="cf">function</span>(b, X, y) <span class="kw">sum</span>((y <span class="op">-</span><span class="st"> </span>X <span class="op">%*%</span><span class="st"> </span>b)<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span>n, X, y), </span>
<span id="cb209-7"><a href="lasso-regression.html#cb209-7"></a>                  <span class="kw">length</span>(beta1), <span class="kw">length</span>(beta2))</span>
<span id="cb209-8"><a href="lasso-regression.html#cb209-8"></a>    </span>
<span id="cb209-9"><a href="lasso-regression.html#cb209-9"></a>    <span class="co"># quantile levels for drawing contour</span></span>
<span id="cb209-10"><a href="lasso-regression.html#cb209-10"></a>    quanlvl =<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.01</span>, <span class="fl">0.025</span>, <span class="fl">0.05</span>, <span class="fl">0.2</span>, <span class="fl">0.5</span>, <span class="fl">0.75</span>)</span>
<span id="cb209-11"><a href="lasso-regression.html#cb209-11"></a>    </span>
<span id="cb209-12"><a href="lasso-regression.html#cb209-12"></a>    <span class="kw">contour</span>(beta1, beta2, rss, <span class="dt">levels =</span> <span class="kw">quantile</span>(rss, quanlvl))</span>
<span id="cb209-13"><a href="lasso-regression.html#cb209-13"></a>    <span class="kw">box</span>()</span>
<span id="cb209-14"><a href="lasso-regression.html#cb209-14"></a>    </span>
<span id="cb209-15"><a href="lasso-regression.html#cb209-15"></a>    <span class="co"># the truth</span></span>
<span id="cb209-16"><a href="lasso-regression.html#cb209-16"></a>    <span class="kw">points</span>(<span class="fl">0.1</span>, <span class="fl">0.5</span>, <span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">cex =</span> <span class="dv">2</span>)</span>
<span id="cb209-17"><a href="lasso-regression.html#cb209-17"></a>    <span class="kw">points</span>(<span class="fl">0.1403512</span>, <span class="fl">0.5686526</span>, <span class="dt">pch =</span> <span class="dv">4</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">cex =</span> <span class="dv">2</span>)</span>
<span id="cb209-18"><a href="lasso-regression.html#cb209-18"></a>    <span class="kw">abline</span>(<span class="dt">h =</span> <span class="dv">0</span>, <span class="dt">col =</span> <span class="st">&quot;deepskyblue&quot;</span>)</span>
<span id="cb209-19"><a href="lasso-regression.html#cb209-19"></a>    <span class="kw">abline</span>(<span class="dt">v =</span> <span class="dv">0</span>, <span class="dt">col =</span> <span class="st">&quot;deepskyblue&quot;</span>)</span></code></pre></div>
<p><img src="3.3-lasso_files/figure-html/unnamed-chunk-2-1.png" width="45%" style="display: block; margin: auto;" /></p>
<p>As an alternative, if we add a Lasso <span class="math inline">\(\ell_1\)</span> penalty, the contour will be changed. The following plot is the contour of the penalty.</p>
<div class="sourceCode" id="cb210"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb210-1"><a href="lasso-regression.html#cb210-1"></a>    pen &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">apply</span>(allbeta, <span class="dv">1</span>, <span class="cf">function</span>(b) <span class="fl">0.2</span><span class="op">*</span><span class="kw">sum</span>(<span class="kw">abs</span>(b))),</span>
<span id="cb210-2"><a href="lasso-regression.html#cb210-2"></a>                  <span class="kw">length</span>(beta1), <span class="kw">length</span>(beta2))</span>
<span id="cb210-3"><a href="lasso-regression.html#cb210-3"></a>    </span>
<span id="cb210-4"><a href="lasso-regression.html#cb210-4"></a>    <span class="kw">contour</span>(beta1, beta2, pen, <span class="dt">levels =</span> <span class="kw">quantile</span>(pen, quanlvl))</span>
<span id="cb210-5"><a href="lasso-regression.html#cb210-5"></a>    <span class="kw">points</span>(<span class="fl">0.1</span>, <span class="fl">0.5</span>, <span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">cex =</span> <span class="dv">2</span>)</span>
<span id="cb210-6"><a href="lasso-regression.html#cb210-6"></a>    <span class="kw">box</span>()</span>
<span id="cb210-7"><a href="lasso-regression.html#cb210-7"></a>    <span class="kw">abline</span>(<span class="dt">h =</span> <span class="dv">0</span>, <span class="dt">col =</span> <span class="st">&quot;deepskyblue&quot;</span>)</span>
<span id="cb210-8"><a href="lasso-regression.html#cb210-8"></a>    <span class="kw">abline</span>(<span class="dt">v =</span> <span class="dv">0</span>, <span class="dt">col =</span> <span class="st">&quot;deepskyblue&quot;</span>)</span></code></pre></div>
<p><img src="3.3-lasso_files/figure-html/unnamed-chunk-3-1.png" width="45%" style="display: block; margin: auto;" /></p>
<p>In addition, since the Lasso penalty is not smooth, the overall objective function will have nondifferenciable points along the axies. We can see that if a sufficiently large penalty is applied, the solution is forced to shrink some parameters to 0. This is again a bias-variance trade-off.</p>
<div class="sourceCode" id="cb211"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb211-1"><a href="lasso-regression.html#cb211-1"></a>    <span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>)) </span>
<span id="cb211-2"><a href="lasso-regression.html#cb211-2"></a></span>
<span id="cb211-3"><a href="lasso-regression.html#cb211-3"></a>    <span class="co"># adding a L2 penalty to the objective function</span></span>
<span id="cb211-4"><a href="lasso-regression.html#cb211-4"></a>    rss &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">apply</span>(allbeta, <span class="dv">1</span>, <span class="cf">function</span>(b, X, y) <span class="kw">sum</span>((y <span class="op">-</span><span class="st"> </span>X <span class="op">%*%</span><span class="st"> </span>b)<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span>n <span class="op">+</span><span class="st"> </span><span class="fl">0.2</span><span class="op">*</span><span class="kw">sum</span>(<span class="kw">abs</span>(b)), X, y),</span>
<span id="cb211-5"><a href="lasso-regression.html#cb211-5"></a>                  <span class="kw">length</span>(beta1), <span class="kw">length</span>(beta2))</span>
<span id="cb211-6"><a href="lasso-regression.html#cb211-6"></a>    </span>
<span id="cb211-7"><a href="lasso-regression.html#cb211-7"></a>    <span class="kw">contour</span>(beta1, beta2, rss, <span class="dt">levels =</span> <span class="kw">quantile</span>(rss, quanlvl))</span>
<span id="cb211-8"><a href="lasso-regression.html#cb211-8"></a>    <span class="kw">points</span>(<span class="fl">0.1</span>, <span class="fl">0.5</span>, <span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">cex =</span> <span class="dv">2</span>)</span>
<span id="cb211-9"><a href="lasso-regression.html#cb211-9"></a>    <span class="kw">abline</span>(<span class="dt">h =</span> <span class="dv">0</span>, <span class="dt">col =</span> <span class="st">&quot;deepskyblue&quot;</span>)</span>
<span id="cb211-10"><a href="lasso-regression.html#cb211-10"></a>    <span class="kw">abline</span>(<span class="dt">v =</span> <span class="dv">0</span>, <span class="dt">col =</span> <span class="st">&quot;deepskyblue&quot;</span>)</span>
<span id="cb211-11"><a href="lasso-regression.html#cb211-11"></a>    <span class="kw">box</span>()</span>
<span id="cb211-12"><a href="lasso-regression.html#cb211-12"></a>    </span>
<span id="cb211-13"><a href="lasso-regression.html#cb211-13"></a>    <span class="co"># adding a larger penalty</span></span>
<span id="cb211-14"><a href="lasso-regression.html#cb211-14"></a>    rss &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">apply</span>(allbeta, <span class="dv">1</span>, <span class="cf">function</span>(b, X, y) <span class="kw">sum</span>((y <span class="op">-</span><span class="st"> </span>X <span class="op">%*%</span><span class="st"> </span>b)<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span>n <span class="op">+</span><span class="st"> </span><span class="fl">0.5</span><span class="op">*</span><span class="kw">sum</span>(<span class="kw">abs</span>(b)), X, y),</span>
<span id="cb211-15"><a href="lasso-regression.html#cb211-15"></a>                  <span class="kw">length</span>(beta1), <span class="kw">length</span>(beta2))</span>
<span id="cb211-16"><a href="lasso-regression.html#cb211-16"></a>    <span class="kw">contour</span>(beta1, beta2, rss, <span class="dt">levels =</span> <span class="kw">quantile</span>(rss, quanlvl))</span>
<span id="cb211-17"><a href="lasso-regression.html#cb211-17"></a>    <span class="kw">points</span>(<span class="fl">0.1</span>, <span class="fl">0.5</span>, <span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">cex =</span> <span class="dv">2</span>)</span>
<span id="cb211-18"><a href="lasso-regression.html#cb211-18"></a>    <span class="kw">abline</span>(<span class="dt">h =</span> <span class="dv">0</span>, <span class="dt">col =</span> <span class="st">&quot;deepskyblue&quot;</span>)</span>
<span id="cb211-19"><a href="lasso-regression.html#cb211-19"></a>    <span class="kw">abline</span>(<span class="dt">v =</span> <span class="dv">0</span>, <span class="dt">col =</span> <span class="st">&quot;deepskyblue&quot;</span>)</span>
<span id="cb211-20"><a href="lasso-regression.html#cb211-20"></a>    <span class="kw">box</span>()</span></code></pre></div>
<p><img src="3.3-lasso_files/figure-html/unnamed-chunk-4-1.png" width="90%" style="display: block; margin: auto;" /></p>
</div>
<div id="example-1-the-prostate-cancer-data-1" class="section level3">
<h3><span class="header-section-number">12.1.2</span> Example 1: The Prostate Cancer Data</h3>
<p>We use the prostate cancer data <code>prostate</code> from the <code>ElemStatLearn</code> package. The dataset contains 8 explainatory variables and one outcome <code>lpsa</code>, the log prostate-specific antigen value.</p>
<div class="sourceCode" id="cb212"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb212-1"><a href="lasso-regression.html#cb212-1"></a>    <span class="kw">library</span>(ElemStatLearn)</span>
<span id="cb212-2"><a href="lasso-regression.html#cb212-2"></a>    <span class="kw">head</span>(prostate)</span></code></pre></div>
<pre><code>##       lcavol  lweight age      lbph svi       lcp gleason pgg45       lpsa train
## 1 -0.5798185 2.769459  50 -1.386294   0 -1.386294       6     0 -0.4307829  TRUE
## 2 -0.9942523 3.319626  58 -1.386294   0 -1.386294       6     0 -0.1625189  TRUE
## 3 -0.5108256 2.691243  74 -1.386294   0 -1.386294       7    20 -0.1625189  TRUE
## 4 -1.2039728 3.282789  58 -1.386294   0 -1.386294       6     0 -0.1625189  TRUE
## 5  0.7514161 3.432373  62 -1.386294   0 -1.386294       6     0  0.3715636  TRUE
## 6 -1.0498221 3.228826  50 -1.386294   0 -1.386294       6     0  0.7654678  TRUE</code></pre>
<p>We fit the model using the <code>glmnet</code> package. The tuning parameter need to be selected using cross-validation with the <code>cv.glmnet</code> function.</p>
<div class="sourceCode" id="cb214"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb214-1"><a href="lasso-regression.html#cb214-1"></a>    <span class="kw">library</span>(glmnet)</span>
<span id="cb214-2"><a href="lasso-regression.html#cb214-2"></a>    <span class="kw">set.seed</span>(<span class="dv">3</span>)</span>
<span id="cb214-3"><a href="lasso-regression.html#cb214-3"></a>    fit2 =<span class="st"> </span><span class="kw">cv.glmnet</span>(<span class="kw">data.matrix</span>(prostate[, <span class="dv">1</span><span class="op">:</span><span class="dv">8</span>]), prostate<span class="op">$</span>lpsa, <span class="dt">nfolds =</span> <span class="dv">10</span>)</span></code></pre></div>
<p>We can obtain the estimated coefficients from the best <span class="math inline">\(\lambda\)</span> value. There are usually two options, <code>lambda.min</code> and <code>lambda.1se</code>. The first one is the value that minimizes the cross-validataion error, the second one is slightly more conservative, which gives larger penalty value with more shrinkage.</p>
<div class="sourceCode" id="cb215"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb215-1"><a href="lasso-regression.html#cb215-1"></a>    <span class="kw">coef</span>(fit2, <span class="dt">s =</span> <span class="st">&quot;lambda.min&quot;</span>)</span></code></pre></div>
<pre><code>## 9 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                         1
## (Intercept)  0.1537694862
## lcavol       0.5071477800
## lweight      0.5455934489
## age         -0.0084065349
## lbph         0.0618168145
## svi          0.5899942922
## lcp          .           
## gleason      0.0009732886
## pgg45        0.0023140828</code></pre>
<div class="sourceCode" id="cb217"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb217-1"><a href="lasso-regression.html#cb217-1"></a>    <span class="kw">coef</span>(fit2, <span class="dt">s =</span> <span class="st">&quot;lambda.1se&quot;</span>)</span></code></pre></div>
<pre><code>## 9 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                     1
## (Intercept) 0.6435469
## lcavol      0.4553889
## lweight     0.3142829
## age         .        
## lbph        .        
## svi         0.3674270
## lcp         .        
## gleason     .        
## pgg45       .</code></pre>
<p>The left plots demonstrates how <span class="math inline">\(\lambda\)</span> changes the cross-validation error. There are two vertical lines, which represents <code>lambda.min</code> and <code>lambda.1se</code> respectively. The right plot shows how <span class="math inline">\(\lambda\)</span> changes the parameter values.</p>
<div class="sourceCode" id="cb219"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb219-1"><a href="lasso-regression.html#cb219-1"></a>    <span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb219-2"><a href="lasso-regression.html#cb219-2"></a>    <span class="kw">plot</span>(fit2)</span>
<span id="cb219-3"><a href="lasso-regression.html#cb219-3"></a>    <span class="kw">plot</span>(fit2<span class="op">$</span>glmnet.fit, <span class="st">&quot;lambda&quot;</span>)</span></code></pre></div>
<p><img src="3.3-lasso_files/figure-html/unnamed-chunk-8-1.png" width="90%" style="display: block; margin: auto;" /></p>
<p>Some other packages can perform the same analysis, for example, the <code>lars</code> package.</p>

</div>
</div>
</div>



</div>
            </section>

          </div>
        </div>
      </div>
<a href="ridge-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="splines.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/teazrq/SMLR/edit/master/3.3-lasso.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["SMLR.pdf"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
